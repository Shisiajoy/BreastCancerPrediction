{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOc6ayaCm+MjPIdihOQ+Oqs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shisiajoy/BreastCancerPrediction/blob/main/testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LOAD THE MODEL AND QUANTIZE"
      ],
      "metadata": {
        "id": "jtmd0NLvpePQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "M93ugffNpZ20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cy6MPzRHAXeq",
        "outputId": "97545074-c6eb-4506-ab55-d5f892108ca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmpfto68fds'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 150, 150, 1), dtype=tf.float32, name='input_layer')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  132631755458512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132631755462208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132631755472592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132631755722064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132631755729456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132631755731744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132631913409072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132631913511248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132631755999536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  132631756002352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ],
      "source": [
        "# Load your trained model\n",
        "model = tf.keras.models.load_model('/content/my_model.keras', compile=False)\n",
        "\n",
        "# Convert the model to TensorFlow Lite format\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Apply quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "quantized_model = converter.convert()\n",
        "\n",
        "# Save the quantized model\n",
        "with open('quantized_model.tflite', 'wb') as f:\n",
        "    f.write(quantized_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the quantized model\n",
        "interpreter = tf.lite.Interpreter(model_path='quantized_model.tflite')\n",
        "\n",
        "# Allocate tensors for the model\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output details (if you want to see the structure)\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"Quantized model loaded and ready for inference!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykb1Fg9OIBTa",
        "outputId": "477bb700-0ed3-495f-b357-38475854f89d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantized model loaded and ready for inference!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming  input image is a (150, 150, 1) grayscale image\n",
        "def preprocess_image(image_path):\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(150, 150), color_mode='grayscale')\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array = img_array.astype('float32') / 255.0  # Normalize to [0, 1]\n",
        "    return img_array\n",
        "\n",
        "# Path to your input image\n",
        "image_path = '/content/10008_1591370361 (1).png'\n",
        "input_data = preprocess_image(image_path)\n",
        "\n",
        "# Set input tensor\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "# Run the model\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get the prediction result\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "#print(\"Prediction:\", output_data)\n",
        "\n",
        "\n",
        "# Assuming 'output_data' contains the prediction probability\n",
        "prediction_probability = output_data[0][0]  # Extract the predicted probability\n",
        "\n",
        "# Define threshold (e.g., 0.5)\n",
        "threshold = 0.5\n",
        "\n",
        "# Determine the class based on the threshold\n",
        "if prediction_probability >= threshold:\n",
        "    prediction_class = \"Cancer\"\n",
        "else:\n",
        "    prediction_class = \"No Cancer\"\n",
        "\n",
        "# Display the result\n",
        "print(f\"Prediction: {prediction_class} with a probability of {prediction_probability:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0g03g6WITzW",
        "outputId": "1abca016-589e-4c8a-da1b-a7942e5357e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: Cancer with a probability of 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pnu7LCorHmGj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}